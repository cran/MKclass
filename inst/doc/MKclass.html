<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Matthias Kohl" />

<meta name="date" content="2020-10-04" />

<title>Package MKclass</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">Package MKclass</h1>
<h4 class="author">Matthias Kohl</h4>
<h4 class="date">2020-10-04</h4>


<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#or-rr-and-other-risk-measures">OR, RR and Other Risk Measures</a></li>
<li><a href="#auc">AUC</a><ul>
<li><a href="#estimation">Estimation</a></li>
<li><a href="#testing">Testing</a></li>
<li><a href="#pairwise">Pairwise</a></li>
</ul></li>
<li><a href="#ppv-and-npv">PPV and NPV</a></li>
<li><a href="#performance-measures-and-scores">Performance Measures and Scores</a></li>
<li><a href="#optimal-cutoff">Optimal Cutoff</a></li>
<li><a href="#hosmer-lemeshow-and-le-cessie-van-houwelingen-copas-hosmer">Hosmer-Lemeshow and le Cessie-van Houwelingen-Copas-Hosmer</a></li>
<li><a href="#sessioninfo">sessionInfo</a></li>
</ul>
</div>

<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Package MKclass includes a collection of functions that I found useful for statistical classification.</p>
<p>We first load the package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MKclass)</code></pre></div>
</div>
<div id="or-rr-and-other-risk-measures" class="section level2">
<h2>OR, RR and Other Risk Measures</h2>
<p>Given the incidence of the outcome of interest in the nonexposed (p0) and exposed (p1) group, several risk measures can be computed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Example from Wikipedia
<span class="kw">risks</span>(<span class="dt">p0 =</span> <span class="fl">0.4</span>, <span class="dt">p1 =</span> <span class="fl">0.1</span>)</code></pre></div>
<pre><code>##        p0        p1        RR        OR       RRR       ARR       NNT 
## 0.4000000 0.1000000 0.2500000 0.1666667 0.7500000 0.3000000 3.3333333</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">risks</span>(<span class="dt">p0 =</span> <span class="fl">0.4</span>, <span class="dt">p1 =</span> <span class="fl">0.5</span>)</code></pre></div>
<pre><code>##    p0    p1    RR    OR   RRI   ARI   NNH 
##  0.40  0.50  1.25  1.50  0.25  0.10 10.00</code></pre>
<p>Given p0 or p1 and OR, we can compute the respective RR.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">or2rr</span>(<span class="dt">or =</span> <span class="fl">1.5</span>, <span class="dt">p0 =</span> <span class="fl">0.4</span>)</code></pre></div>
<pre><code>## [1] 1.25</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">or2rr</span>(<span class="dt">or =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>, <span class="dt">p1 =</span> <span class="fl">0.1</span>)</code></pre></div>
<pre><code>## [1] 0.25</code></pre>
<p>There is also a function for computing an approximate confidence interval for the relative risk (RR).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Example from Wikipedia
<span class="kw">rrCI</span>(<span class="dt">a =</span> <span class="dv">15</span>, <span class="dt">b =</span> <span class="dv">135</span>, <span class="dt">c =</span> <span class="dv">100</span>, <span class="dt">d =</span> <span class="dv">150</span>)</code></pre></div>
<pre><code>## $estimate
## relative risk 
##          0.25 
## 
## $conf.int
##                   2.5 %    97.5 %
## relative risk 0.1510993 0.4136353
## attr(,&quot;conf.level&quot;)
## [1] 0.95
## 
## $method
## [1] &quot;asymptotic confidence interval&quot;
## 
## attr(,&quot;class&quot;)
## [1] &quot;confint&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rrCI</span>(<span class="dt">a =</span> <span class="dv">75</span>, <span class="dt">b =</span> <span class="dv">75</span>, <span class="dt">c =</span> <span class="dv">100</span>, <span class="dt">d =</span> <span class="dv">150</span>)</code></pre></div>
<pre><code>## $estimate
## relative risk 
##          1.25 
## 
## $conf.int
##                 2.5 %  97.5 %
## relative risk 1.00256 1.55851
## attr(,&quot;conf.level&quot;)
## [1] 0.95
## 
## $method
## [1] &quot;asymptotic confidence interval&quot;
## 
## attr(,&quot;class&quot;)
## [1] &quot;confint&quot;</code></pre>
</div>
<div id="auc" class="section level2">
<h2>AUC</h2>
<div id="estimation" class="section level3">
<h3>Estimation</h3>
<p>There are two functions that can be used to calculate and test AUC values. First function AUC, which computes the area under the receiver operating characteristic curve (AUC under ROC curve) using the connection of AUC to the Wilcoxon rank sum test. We use some random data and groups to demonstrate the use of this function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">runif</span>(<span class="dv">50</span>, <span class="dt">max =</span> <span class="fl">0.6</span>), <span class="kw">runif</span>(<span class="dv">50</span>, <span class="dt">min =</span> <span class="fl">0.4</span>))
g &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">50</span>))
<span class="kw">AUC</span>(x, <span class="dt">group =</span> g)</code></pre></div>
<pre><code>## area under curve (AUC) 
##                 0.9576</code></pre>
<p>Sometimes the labels of the group should be switched to avoid an AUC smaller than 0.5, which represents a result worse than a pure random choice.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">50</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">50</span>))
<span class="kw">AUC</span>(x, <span class="dt">group =</span> g)</code></pre></div>
<pre><code>## Warning in AUC(x, group = g): The computed AUC value 0.0424 will be replaced by
## 0.9576 which can be achieved be interchanging the sample labels!</code></pre>
<pre><code>## area under curve (AUC) 
##                 0.9576</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## no switching
<span class="kw">AUC</span>(x, <span class="dt">group =</span> g, <span class="dt">switchAUC =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## area under curve (AUC) 
##                 0.0424</code></pre>
</div>
<div id="testing" class="section level3">
<h3>Testing</h3>
<p>We can also perform statistical tests for AUC. First, the one-sample test which corresponds to the Wilcoxon signed rank test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">g &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">50</span>))
<span class="kw">AUC.test</span>(<span class="dt">pred1 =</span> x, <span class="dt">lab1 =</span> g)</code></pre></div>
<pre><code>## $Variable1
##        AUC         SE     low CI      up CI 
## 0.95760000 0.02092592 0.91658595 0.99861405 
## 
## $Test
## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  0 and 1
## W = 106, p-value = 3.194e-15
## alternative hypothesis: true AUC is not equal to 0.5</code></pre>
<p>We can also compare two AUC using the test of Hanley and McNeil (1982).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">runif</span>(<span class="dv">50</span>, <span class="dt">max =</span> <span class="fl">0.7</span>), <span class="kw">runif</span>(<span class="dv">50</span>, <span class="dt">min =</span> <span class="fl">0.3</span>))
g2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">50</span>))
<span class="kw">AUC.test</span>(<span class="dt">pred1 =</span> x, <span class="dt">lab1 =</span> g, <span class="dt">pred2 =</span> x2, <span class="dt">lab2 =</span> g2)</code></pre></div>
<pre><code>## $Variable1
##        AUC         SE     low CI      up CI 
## 0.95760000 0.02092592 0.91658595 0.99861405 
## 
## $Variable2
##        AUC         SE     low CI      up CI 
## 0.82080000 0.04238554 0.73772586 0.90387414 
## 
## $Test
## 
##  Hanley and McNeil test for two AUCs
## 
## data:  x and x2
## z = 2.894, p-value = 0.003803
## alternative hypothesis: true difference in AUC is not equal to 0
## 95 percent confidence interval:
##  0.04415301 0.22944699
## sample estimates:
## Difference in AUC 
##            0.1368</code></pre>
</div>
<div id="pairwise" class="section level3">
<h3>Pairwise</h3>
<p>There is also a function for pairwise comparison if there are more than two groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x3 &lt;-<span class="st"> </span><span class="kw">c</span>(x, x2)
g3 &lt;-<span class="st"> </span><span class="kw">c</span>(g, <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">2</span>, <span class="dv">50</span>), <span class="kw">rep</span>(<span class="dv">3</span>, <span class="dv">50</span>)))
<span class="kw">pairwise.auc</span>(<span class="dt">x =</span> x3, <span class="dt">g =</span> g3)</code></pre></div>
<pre><code>## Warning in AUC(xi, xj): The computed AUC value 0.0424 will be replaced by 0.9576
## which can be achieved be interchanging the sample labels!</code></pre>
<pre><code>## Warning in AUC(xi, xj): The computed AUC value 0.4176 will be replaced by 0.5824
## which can be achieved be interchanging the sample labels!</code></pre>
<pre><code>## Warning in AUC(xi, xj): The computed AUC value 0.1272 will be replaced by 0.8728
## which can be achieved be interchanging the sample labels!</code></pre>
<pre><code>## Warning in AUC(xi, xj): The computed AUC value 0.1792 will be replaced by 0.8208
## which can be achieved be interchanging the sample labels!</code></pre>
<pre><code>## 0 vs 1 0 vs 2 0 vs 3 1 vs 2 1 vs 3 2 vs 3 
## 0.9576 0.5824 0.8728 0.9028 0.6376 0.8208</code></pre>
</div>
</div>
<div id="ppv-and-npv" class="section level2">
<h2>PPV and NPV</h2>
<p>In case of medical diagnostic tests, usually sensitivity and specificity of the tests are known and there is also at least a rough estimate of the prevalence of the tested disease. In the practival application, the positive predictive value (PPV) and the negative predictive value are of crucial importance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Example: HIV test 
## 1. ELISA screening test (4th generation)
<span class="kw">predValues</span>(<span class="dt">sens =</span> <span class="fl">0.999</span>, <span class="dt">spec =</span> <span class="fl">0.998</span>, <span class="dt">prev =</span> <span class="fl">0.001</span>)</code></pre></div>
<pre><code>##       PPV       NPV 
## 0.3333333 0.9999990</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## 2. Western-Plot confirmation test
<span class="kw">predValues</span>(<span class="dt">sens =</span> <span class="fl">0.998</span>, <span class="dt">spec =</span> <span class="fl">0.999996</span>, <span class="dt">prev =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)</code></pre></div>
<pre><code>##      PPV      NPV 
## 0.999992 0.999001</code></pre>
</div>
<div id="performance-measures-and-scores" class="section level2">
<h2>Performance Measures and Scores</h2>
<p>In the development of diagnostic tests and more general in binary classification a variety of performance measures and scores can be found in literature. Functions perfMeasures and prefScores compute several of them.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## example from dataset infert
fit &lt;-<span class="st"> </span><span class="kw">glm</span>(case <span class="op">~</span><span class="st"> </span>spontaneous<span class="op">+</span>induced, <span class="dt">data =</span> infert, <span class="dt">family =</span> <span class="kw">binomial</span>())
pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)

## with group numbers
<span class="kw">perfMeasures</span>(pred, <span class="dt">truth =</span> infert<span class="op">$</span>case, <span class="dt">namePos =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>## 
##      Performance Measure(s)
## 
##                                        Measure      Value
## 1                               accuracy (ACC) 0.71370968
## 2  probability of correct classification (PCC) 0.71370968
## 3                        fraction correct (FC) 0.71370968
## 4            simple matching coefficient (SMC) 0.71370968
## 5                Rand (similarity) index (RSI) 0.71370968
## 6       probability of misclassification (PMC) 0.28629032
## 7                              error rate (ER) 0.28629032
## 8                     fraction incorrect (FIC) 0.28629032
## 9                           sensitivity (SENS) 0.33734940
## 10                                recall (REC) 0.33734940
## 11                    true positive rate (TPR) 0.33734940
## 12               probability of detection (PD) 0.33734940
## 13                               hit rate (HR) 0.33734940
## 14                          specificity (SPEC) 0.90303030
## 15                    true negative rate (TNR) 0.90303030
## 16                           selectivity (SEL) 0.90303030
## 17                         detection rate (DR) 0.11290323
## 18                   false positive rate (FPR) 0.09696970
## 19                               fall-out (FO) 0.09696970
## 20                    false alarm (rate) (FAR) 0.09696970
## 21            probability of false alarm (PFA) 0.09696970
## 22                   false negative rate (FNR) 0.66265060
## 23                              miss rate (MR) 0.66265060
## 24                  false discovery rate (FDR) 0.36363636
## 25                   false omission rate (FOR) 0.26960784
## 26                           prevalence (PREV) 0.33467742
## 27      (positive) pre-test probability (PREP) 0.33467742
## 28             (positive) pre-test odds (PREO) 0.50303030
## 29                detection prevalence (DPREV) 0.17741935
## 30       negative pre-test probability (NPREP) 0.66532258
## 31              negative pre-test odds (NPREO) 1.98795181
## 32                   no information rate (NIR) 0.66532258
## 33                    weighted accuracy (WACC) 0.62018985
## 34                    balanced accuracy (BACC) 0.62018985
## 35              (bookmaker) informedness (INF) 0.24037970
## 36                  Youden's J statistic (YJS) 0.24037970
## 37                               deltap' (DPp) 0.24037970
## 38             positive likelihood ratio (PLR) 3.47891566
## 39             negative likelihood ratio (NLR) 0.73380771
## 40             weighted likelihood ratio (WLR) 2.10636169
## 41             balanced likelihood ratio (BLR) 2.10636169
## 42                 diagnostic odds ratio (DOR) 4.74090909
## 43             positive predictive value (PPV) 0.63636364
## 44                            precision (PREC) 0.63636364
## 45    (positive) post-test probability (POSTP) 0.63636364
## 46           (positive) post-test odds (POSTO) 1.75000000
## 47                      Bayes factor G1 (BFG1) 3.47891566
## 48             negative predictive value (NPV) 0.73039216
## 49     negative post-test probability (NPOSTP) 0.73039216
## 50            negative post-test odds (NPOSTO) 2.70909091
## 51                      Bayes factor G0 (BFG0) 1.36275482
## 52                           markedness (MARK) 0.36675579
## 53                                 deltap (DP) 0.36675579
## 54             weighted predictive value (WPV) 0.68337790
## 55             balanced predictive value (BPV) 0.68337790
## 56                              F1 score (F1S) 0.44094488
## 57           Dice similarity coefficient (DSC) 0.44094488
## 58                          F beta score (FBS) 0.44094488
## 59        Jaccard similarity coefficient (JSC) 0.28282828
## 60                           threat score (TS) 0.28282828
## 61                critical success index (CSI) 0.28282828
## 62     Matthews' correlation coefficient (MCC) 0.29691859
## 63        Pearson's correlation (r phi) (RPHI) 0.29691859
## 64                      Phi coefficient (PHIC) 0.29691859
## 65                            Cramer's V (CRV) 0.29691859
## 66    proportion of positive predictions (PPP) 0.17741935
## 67                    expected accuracy (EACC) 0.60665973
## 68             Cohen's kappa coefficient (CKC) 0.27215608
## 69            mutual information in bits (MI2) 0.06014644
## 70                 joint entropy in bits (JE2) 1.06320911
## 71      variation of information in bits (VI2) 1.47374006
## 72                       Jaccard distance (JD) 0.96078821
## 73           information quality ratio (INFQR) 0.03921179
## 74                uncertainty coefficient (UC) 0.06540258
## 75                    entropy coefficient (EC) 0.06540258
## 76                 proficiency (metric) (PROF) 0.06540258
## 77                   deficiency (metric) (DFM) 0.93459742
## 78                            redundancy (RED) 0.03773224
## 79                  symmetric uncertainty (SU) 0.07546449
## 80                 normalized uncertainty (NU) 0.07637373</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">perfScores</span>(pred, <span class="dt">truth =</span> infert<span class="op">$</span>case, <span class="dt">namePos =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>## 
##      Performance Score(s)
## 
##                        Score     Value
## 1     area under curve (AUC) 0.7285506
## 2          Gini index (GINI) 0.4571011
## 3           Brier score (BS) 0.1911729
## 4 positive Brier score (PBS) 0.3605069
## 5 negative Brier score (NBS) 0.1059928
## 6 weighted Brier score (WBS) 0.2332498
## 7 balanced Brier score (BBS) 0.2332498</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## with group names
my.case &lt;-<span class="st"> </span><span class="kw">factor</span>(infert<span class="op">$</span>case, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;control&quot;</span>, <span class="st">&quot;case&quot;</span>))
<span class="kw">perfMeasures</span>(pred, <span class="dt">truth =</span> my.case, <span class="dt">namePos =</span> <span class="st">&quot;case&quot;</span>)</code></pre></div>
<pre><code>## 
##      Performance Measure(s)
## 
##                                        Measure      Value
## 1                               accuracy (ACC) 0.71370968
## 2  probability of correct classification (PCC) 0.71370968
## 3                        fraction correct (FC) 0.71370968
## 4            simple matching coefficient (SMC) 0.71370968
## 5                Rand (similarity) index (RSI) 0.71370968
## 6       probability of misclassification (PMC) 0.28629032
## 7                              error rate (ER) 0.28629032
## 8                     fraction incorrect (FIC) 0.28629032
## 9                           sensitivity (SENS) 0.33734940
## 10                                recall (REC) 0.33734940
## 11                    true positive rate (TPR) 0.33734940
## 12               probability of detection (PD) 0.33734940
## 13                               hit rate (HR) 0.33734940
## 14                          specificity (SPEC) 0.90303030
## 15                    true negative rate (TNR) 0.90303030
## 16                           selectivity (SEL) 0.90303030
## 17                         detection rate (DR) 0.11290323
## 18                   false positive rate (FPR) 0.09696970
## 19                               fall-out (FO) 0.09696970
## 20                    false alarm (rate) (FAR) 0.09696970
## 21            probability of false alarm (PFA) 0.09696970
## 22                   false negative rate (FNR) 0.66265060
## 23                              miss rate (MR) 0.66265060
## 24                  false discovery rate (FDR) 0.36363636
## 25                   false omission rate (FOR) 0.26960784
## 26                           prevalence (PREV) 0.33467742
## 27      (positive) pre-test probability (PREP) 0.33467742
## 28             (positive) pre-test odds (PREO) 0.50303030
## 29                detection prevalence (DPREV) 0.17741935
## 30       negative pre-test probability (NPREP) 0.66532258
## 31              negative pre-test odds (NPREO) 1.98795181
## 32                   no information rate (NIR) 0.66532258
## 33                    weighted accuracy (WACC) 0.62018985
## 34                    balanced accuracy (BACC) 0.62018985
## 35              (bookmaker) informedness (INF) 0.24037970
## 36                  Youden's J statistic (YJS) 0.24037970
## 37                               deltap' (DPp) 0.24037970
## 38             positive likelihood ratio (PLR) 3.47891566
## 39             negative likelihood ratio (NLR) 0.73380771
## 40             weighted likelihood ratio (WLR) 2.10636169
## 41             balanced likelihood ratio (BLR) 2.10636169
## 42                 diagnostic odds ratio (DOR) 4.74090909
## 43             positive predictive value (PPV) 0.63636364
## 44                            precision (PREC) 0.63636364
## 45    (positive) post-test probability (POSTP) 0.63636364
## 46           (positive) post-test odds (POSTO) 1.75000000
## 47                      Bayes factor G1 (BFG1) 3.47891566
## 48             negative predictive value (NPV) 0.73039216
## 49     negative post-test probability (NPOSTP) 0.73039216
## 50            negative post-test odds (NPOSTO) 2.70909091
## 51                      Bayes factor G0 (BFG0) 1.36275482
## 52                           markedness (MARK) 0.36675579
## 53                                 deltap (DP) 0.36675579
## 54             weighted predictive value (WPV) 0.68337790
## 55             balanced predictive value (BPV) 0.68337790
## 56                              F1 score (F1S) 0.44094488
## 57           Dice similarity coefficient (DSC) 0.44094488
## 58                          F beta score (FBS) 0.44094488
## 59        Jaccard similarity coefficient (JSC) 0.28282828
## 60                           threat score (TS) 0.28282828
## 61                critical success index (CSI) 0.28282828
## 62     Matthews' correlation coefficient (MCC) 0.29691859
## 63        Pearson's correlation (r phi) (RPHI) 0.29691859
## 64                      Phi coefficient (PHIC) 0.29691859
## 65                            Cramer's V (CRV) 0.29691859
## 66    proportion of positive predictions (PPP) 0.17741935
## 67                    expected accuracy (EACC) 0.60665973
## 68             Cohen's kappa coefficient (CKC) 0.27215608
## 69            mutual information in bits (MI2) 0.06014644
## 70                 joint entropy in bits (JE2) 1.06320911
## 71      variation of information in bits (VI2) 1.47374006
## 72                       Jaccard distance (JD) 0.96078821
## 73           information quality ratio (INFQR) 0.03921179
## 74                uncertainty coefficient (UC) 0.06540258
## 75                    entropy coefficient (EC) 0.06540258
## 76                 proficiency (metric) (PROF) 0.06540258
## 77                   deficiency (metric) (DFM) 0.93459742
## 78                            redundancy (RED) 0.03773224
## 79                  symmetric uncertainty (SU) 0.07546449
## 80                 normalized uncertainty (NU) 0.07637373</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">perfScores</span>(pred, <span class="dt">truth =</span> my.case, <span class="dt">namePos =</span> <span class="st">&quot;case&quot;</span>)</code></pre></div>
<pre><code>## 
##      Performance Score(s)
## 
##                        Score     Value
## 1     area under curve (AUC) 0.7285506
## 2          Gini index (GINI) 0.4571011
## 3           Brier score (BS) 0.1911729
## 4 positive Brier score (PBS) 0.3605069
## 5 negative Brier score (NBS) 0.1059928
## 6 weighted Brier score (WBS) 0.2332498
## 7 balanced Brier score (BBS) 0.2332498</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## using weights
<span class="kw">perfMeasures</span>(pred, <span class="dt">truth =</span> infert<span class="op">$</span>case, <span class="dt">namePos =</span> <span class="dv">1</span>, <span class="dt">weight =</span> <span class="fl">0.3</span>)</code></pre></div>
<pre><code>## 
##      Performance Measure(s)
## 
##                                        Measure      Value
## 1                               accuracy (ACC) 0.71370968
## 2  probability of correct classification (PCC) 0.71370968
## 3                        fraction correct (FC) 0.71370968
## 4            simple matching coefficient (SMC) 0.71370968
## 5                Rand (similarity) index (RSI) 0.71370968
## 6       probability of misclassification (PMC) 0.28629032
## 7                              error rate (ER) 0.28629032
## 8                     fraction incorrect (FIC) 0.28629032
## 9                           sensitivity (SENS) 0.33734940
## 10                                recall (REC) 0.33734940
## 11                    true positive rate (TPR) 0.33734940
## 12               probability of detection (PD) 0.33734940
## 13                               hit rate (HR) 0.33734940
## 14                          specificity (SPEC) 0.90303030
## 15                    true negative rate (TNR) 0.90303030
## 16                           selectivity (SEL) 0.90303030
## 17                         detection rate (DR) 0.11290323
## 18                   false positive rate (FPR) 0.09696970
## 19                               fall-out (FO) 0.09696970
## 20                    false alarm (rate) (FAR) 0.09696970
## 21            probability of false alarm (PFA) 0.09696970
## 22                   false negative rate (FNR) 0.66265060
## 23                              miss rate (MR) 0.66265060
## 24                  false discovery rate (FDR) 0.36363636
## 25                   false omission rate (FOR) 0.26960784
## 26                           prevalence (PREV) 0.33467742
## 27      (positive) pre-test probability (PREP) 0.33467742
## 28             (positive) pre-test odds (PREO) 0.50303030
## 29                detection prevalence (DPREV) 0.17741935
## 30       negative pre-test probability (NPREP) 0.66532258
## 31              negative pre-test odds (NPREO) 1.98795181
## 32                   no information rate (NIR) 0.66532258
## 33                    weighted accuracy (WACC) 0.73332603
## 34                    balanced accuracy (BACC) 0.62018985
## 35              (bookmaker) informedness (INF) 0.24037970
## 36                  Youden's J statistic (YJS) 0.24037970
## 37                               deltap' (DPp) 0.24037970
## 38             positive likelihood ratio (PLR) 3.47891566
## 39             negative likelihood ratio (NLR) 0.73380771
## 40             weighted likelihood ratio (WLR) 1.55734010
## 41             balanced likelihood ratio (BLR) 2.10636169
## 42                 diagnostic odds ratio (DOR) 4.74090909
## 43             positive predictive value (PPV) 0.63636364
## 44                            precision (PREC) 0.63636364
## 45    (positive) post-test probability (POSTP) 0.63636364
## 46           (positive) post-test odds (POSTO) 1.75000000
## 47                      Bayes factor G1 (BFG1) 3.47891566
## 48             negative predictive value (NPV) 0.73039216
## 49     negative post-test probability (NPOSTP) 0.73039216
## 50            negative post-test odds (NPOSTO) 2.70909091
## 51                      Bayes factor G0 (BFG0) 1.36275482
## 52                           markedness (MARK) 0.36675579
## 53                                 deltap (DP) 0.36675579
## 54             weighted predictive value (WPV) 0.70218360
## 55             balanced predictive value (BPV) 0.68337790
## 56                              F1 score (F1S) 0.44094488
## 57           Dice similarity coefficient (DSC) 0.44094488
## 58                          F beta score (FBS) 0.44094488
## 59        Jaccard similarity coefficient (JSC) 0.28282828
## 60                           threat score (TS) 0.28282828
## 61                critical success index (CSI) 0.28282828
## 62     Matthews' correlation coefficient (MCC) 0.29691859
## 63        Pearson's correlation (r phi) (RPHI) 0.29691859
## 64                      Phi coefficient (PHIC) 0.29691859
## 65                            Cramer's V (CRV) 0.29691859
## 66    proportion of positive predictions (PPP) 0.17741935
## 67                    expected accuracy (EACC) 0.60665973
## 68             Cohen's kappa coefficient (CKC) 0.27215608
## 69            mutual information in bits (MI2) 0.06014644
## 70                 joint entropy in bits (JE2) 1.06320911
## 71      variation of information in bits (VI2) 1.47374006
## 72                       Jaccard distance (JD) 0.96078821
## 73           information quality ratio (INFQR) 0.03921179
## 74                uncertainty coefficient (UC) 0.06540258
## 75                    entropy coefficient (EC) 0.06540258
## 76                 proficiency (metric) (PROF) 0.06540258
## 77                   deficiency (metric) (DFM) 0.93459742
## 78                            redundancy (RED) 0.03773224
## 79                  symmetric uncertainty (SU) 0.07546449
## 80                 normalized uncertainty (NU) 0.07637373</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">perfScores</span>(pred, <span class="dt">truth =</span> infert<span class="op">$</span>case, <span class="dt">namePos =</span> <span class="dv">1</span>, <span class="dt">wBS =</span> <span class="fl">0.3</span>)</code></pre></div>
<pre><code>## 
##      Performance Score(s)
## 
##                        Score     Value
## 1     area under curve (AUC) 0.7285506
## 2          Gini index (GINI) 0.4571011
## 3           Brier score (BS) 0.1911729
## 4 positive Brier score (PBS) 0.3605069
## 5 negative Brier score (NBS) 0.1059928
## 6 weighted Brier score (WBS) 0.1823470
## 7 balanced Brier score (BBS) 0.2332498</code></pre>
</div>
<div id="optimal-cutoff" class="section level2">
<h2>Optimal Cutoff</h2>
<p>The function optCutoff computes the optimal cutoff for various performance measures for binary classification. More precisely, all performance measures that are implemented in function perfMeasures.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## example from dataset infert
fit &lt;-<span class="st"> </span><span class="kw">glm</span>(case <span class="op">~</span><span class="st"> </span>spontaneous<span class="op">+</span>induced, <span class="dt">data =</span> infert, <span class="dt">family =</span> <span class="kw">binomial</span>())
pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
<span class="kw">optCutoff</span>(pred, <span class="dt">truth =</span> infert<span class="op">$</span>case, <span class="dt">namePos =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>## Optimal Cut-off             YJS 
##       0.3750400       0.3474991</code></pre>
<p>The computation of an optimal cut-off doesn't make any sense for continuous scoring rules as their computation does not involve any cut-off (discretization/dichotomization).</p>
</div>
<div id="hosmer-lemeshow-and-le-cessie-van-houwelingen-copas-hosmer" class="section level2">
<h2>Hosmer-Lemeshow and le Cessie-van Houwelingen-Copas-Hosmer</h2>
<p>These tests are used to investigate the goodness of fit in logistic regression.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Hosmer-Lemeshow goodness of fit tests for C and H statistic 
<span class="kw">HLgof.test</span>(<span class="dt">fit =</span> pred, <span class="dt">obs =</span> infert<span class="op">$</span>case)</code></pre></div>
<pre><code>## Warning in HLgof.test(fit = pred, obs = infert$case): Found only 6 different
## groups for Hosmer-Lemesho C statistic.</code></pre>
<pre><code>## $C
## 
##  Hosmer-Lemeshow C statistic
## 
## data:  pred and infert$case
## X-squared = 4.4272, df = 4, p-value = 0.3513
## 
## 
## $H
## 
##  Hosmer-Lemeshow H statistic
## 
## data:  pred and infert$case
## X-squared = 6.3168, df = 8, p-value = 0.6118</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## e Cessie-van Houwelingen-Copas-Hosmer global goodness of fit test
<span class="kw">HLgof.test</span>(<span class="dt">fit =</span> pred, <span class="dt">obs =</span> infert<span class="op">$</span>case, 
           <span class="dt">X =</span> <span class="kw">model.matrix</span>(case <span class="op">~</span><span class="st"> </span>spontaneous<span class="op">+</span>induced, <span class="dt">data =</span> infert))</code></pre></div>
<pre><code>## Warning in HLgof.test(fit = pred, obs = infert$case, X = model.matrix(case ~ :
## Found only 6 different groups for Hosmer-Lemesho C statistic.</code></pre>
<pre><code>## $C
## 
##  Hosmer-Lemeshow C statistic
## 
## data:  pred and infert$case
## X-squared = 4.4272, df = 4, p-value = 0.3513
## 
## 
## $H
## 
##  Hosmer-Lemeshow H statistic
## 
## data:  pred and infert$case
## X-squared = 6.3168, df = 8, p-value = 0.6118
## 
## 
## $gof
## 
##  le Cessie-van Houwelingen-Copas-Hosmer global goodness of fit test
## 
## data:  pred and infert$case
## z = 1.7533, p-value = 0.07954</code></pre>
</div>
<div id="sessioninfo" class="section level2">
<h2>sessionInfo</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>## R version 4.0.3 RC (2020-10-02 r79291)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Linux Mint 19.3
## 
## Matrix products: default
## BLAS:   /usr/lib/x86_64-linux-gnu/libf77blas.so.3.10.3
## LAPACK: /home/kohlm/RTOP/Rbranch/lib/libRlapack.so
## 
## locale:
##  [1] LC_CTYPE=de_DE.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=de_DE.UTF-8        LC_COLLATE=C              
##  [5] LC_MONETARY=de_DE.UTF-8    LC_MESSAGES=de_DE.UTF-8   
##  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=de_DE.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] MKclass_0.3
## 
## loaded via a namespace (and not attached):
##  [1] compiler_4.0.3  magrittr_1.5    htmltools_0.5.0 tools_4.0.3    
##  [5] yaml_2.2.1      stringi_1.4.6   rmarkdown_2.3   knitr_1.29     
##  [9] stringr_1.4.0   digest_0.6.25   xfun_0.16       rlang_0.4.7    
## [13] evaluate_0.14</code></pre>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
